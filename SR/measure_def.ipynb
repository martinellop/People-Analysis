{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leonardo\\anaconda3\\envs\\generic\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import imagenhancer as ie\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt \n",
    "import cv2 as cv\n",
    "import sys\n",
    "sys.argv = ['']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToDo:\n",
    "## Visual quality\n",
    "taking a set of 4/5 images in LR (set5?), and augmenting the resolution with bicubic interpolation,something and real-esrgan\n",
    "\n",
    "## Retrieval performance\n",
    "Do the same thing, but the starting image is a degradated one (jerk)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### degrading images for simulating low res bb for a \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: 44, H: 122\n",
      "W: 47, H: 136\n",
      "W: 38, H: 116\n",
      "W: 61, H: 179\n",
      "W: 52, H: 172\n",
      "W: 45, H: 132\n",
      "W: 48, H: 160\n",
      "W: 45, H: 128\n",
      "W: 55, H: 137\n",
      "W: 55, H: 176\n",
      "W: 41, H: 120\n",
      "W: 54, H: 190\n",
      "W: 43, H: 111\n",
      "W: 44, H: 129\n",
      "W: 38, H: 116\n",
      "W: 41, H: 116\n",
      "W: 50, H: 179\n"
     ]
    }
   ],
   "source": [
    "for img in os.listdir(\".\\\\reid\\\\CelebREID_empty\\\\testImages\\\\SR\\\\\"):\n",
    "    path = \".\\\\reid\\\\CelebREID_empty\\\\testImages\\\\SR\\\\\"+img\n",
    "    starting_image = cv.cvtColor(cv.imread(path),cv.COLOR_BGR2RGB)\n",
    "    deg_img = ie.downscale(starting_image,2)\n",
    "    # plt.imshow(deg_img)\n",
    "    cv.imwrite(r'.\\reid\\CelebREID_empty\\testImages'+f\"\\\\{img}\", cv.cvtColor(deg_img,cv.COLOR_RGB2BGR))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform all the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img: (122, 44)\n",
      "UP: (244, 88)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leonardo\\AppData\\Local\\Temp\\ipykernel_8152\\4065359047.py:19: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if res == img:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UP_filt: (244, 88)\n",
      "filt_UP: (244, 88)\n",
      "Bicubic: (244, 88)\n",
      "img: (136, 47)\n",
      "UP: (272, 94)\n",
      "UP_filt: (272, 94)\n",
      "filt_UP: (272, 94)\n",
      "Bicubic: (272, 94)\n",
      "img: (116, 38)\n",
      "UP: (232, 76)\n",
      "UP_filt: (232, 76)\n",
      "filt_UP: (232, 76)\n",
      "Bicubic: (232, 76)\n",
      "img: (179, 61)\n",
      "UP: (358, 122)\n",
      "UP_filt: (358, 122)\n",
      "filt_UP: (358, 122)\n",
      "Bicubic: (358, 122)\n",
      "img: (172, 52)\n",
      "UP: (344, 104)\n",
      "UP_filt: (344, 104)\n",
      "filt_UP: (344, 104)\n",
      "Bicubic: (344, 104)\n",
      "img: (132, 45)\n",
      "UP: (264, 90)\n",
      "UP_filt: (264, 90)\n",
      "filt_UP: (264, 90)\n",
      "Bicubic: (264, 90)\n",
      "img: (160, 48)\n",
      "UP: (320, 96)\n",
      "UP_filt: (320, 96)\n",
      "filt_UP: (320, 96)\n",
      "Bicubic: (320, 96)\n",
      "img: (128, 45)\n",
      "UP: (256, 90)\n",
      "UP_filt: (256, 90)\n",
      "filt_UP: (256, 90)\n",
      "Bicubic: (256, 90)\n",
      "img: (137, 55)\n",
      "UP: (274, 110)\n",
      "UP_filt: (274, 110)\n",
      "filt_UP: (274, 110)\n",
      "Bicubic: (274, 110)\n",
      "img: (176, 55)\n",
      "UP: (352, 110)\n",
      "UP_filt: (352, 110)\n",
      "filt_UP: (352, 110)\n",
      "Bicubic: (352, 110)\n",
      "img: (120, 41)\n",
      "UP: (240, 82)\n",
      "UP_filt: (240, 82)\n",
      "filt_UP: (240, 82)\n",
      "Bicubic: (240, 82)\n",
      "img: (190, 54)\n",
      "UP: (380, 108)\n",
      "UP_filt: (380, 108)\n",
      "filt_UP: (380, 108)\n",
      "Bicubic: (380, 108)\n",
      "img: (111, 43)\n",
      "UP: (222, 86)\n",
      "UP_filt: (222, 86)\n",
      "filt_UP: (222, 86)\n",
      "Bicubic: (222, 86)\n",
      "img: (129, 44)\n",
      "UP: (258, 88)\n",
      "UP_filt: (258, 88)\n",
      "filt_UP: (258, 88)\n",
      "Bicubic: (258, 88)\n",
      "img: (116, 38)\n",
      "UP: (232, 76)\n",
      "UP_filt: (232, 76)\n",
      "filt_UP: (232, 76)\n",
      "Bicubic: (232, 76)\n",
      "img: (116, 41)\n",
      "UP: (232, 82)\n",
      "UP_filt: (232, 82)\n",
      "filt_UP: (232, 82)\n",
      "Bicubic: (232, 82)\n",
      "img: (179, 50)\n",
      "UP: (358, 100)\n",
      "UP_filt: (358, 100)\n",
      "filt_UP: (358, 100)\n",
      "Bicubic: (358, 100)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import cv2 as cv\n",
    "import imagenhancer as ie\n",
    "\n",
    "model_path_x2 = '.\\\\RealESRGANmaster\\\\weights\\\\RealESRGAN_x2plus.pth'\n",
    "enhancer = ie.RealESRGANx2(model_path = model_path_x2,scale_= 2)\n",
    "op_list=[\"UP\",\"UP_FILT\",\"FILT_UP\",\"BICUBIC\"]\n",
    "TEST_DIR = os.path.abspath(os.getcwd())+r\"\\reid\\CelebREID_empty\\testimages\"\n",
    "for i in os.listdir(TEST_DIR):\n",
    "    if i[-4:] == '.jpg':\n",
    "        # immagine downgradata\n",
    "        img = cv.cvtColor(cv.imread(TEST_DIR+\"\\\\\"+i), cv.COLOR_BGR2RGB)\n",
    "        print(f\"img: {img.shape[:2]}\")\n",
    "        res = img\n",
    "        for ind, op in enumerate(op_list):\n",
    "            if op == \"UP\":\n",
    "                res = enhancer.upscale(img)\n",
    "                print(f\"UP: {res.shape[:2]}\")\n",
    "                if res == img:\n",
    "                    print(\"ERROR\")\n",
    "\n",
    "            \n",
    "            elif op == \"FILT_UP\":\n",
    "                res = enhancer.filt_up(img)\n",
    "                print(f\"filt_UP: {res.shape[:2]}\")\n",
    "            \n",
    "            elif op == \"UP_FILT\":\n",
    "                res = enhancer.up_filt(img)\n",
    "                print(f\"UP_filt: {res.shape[:2]}\")\n",
    "            \n",
    "            elif op==\"BICUBIC\":\n",
    "                dim0 = int(img.shape[0]*2)\n",
    "                dim1 = int(img.shape[1]*2)\n",
    "                res = cv.resize(img,(dim1,dim0), interpolation=cv.INTER_CUBIC)\n",
    "                print(f\"Bicubic: {res.shape[:2]}\")\n",
    "            \n",
    "\n",
    "            res_filename = TEST_DIR+\"\\\\\"+op+\"\\\\\"+i\n",
    "            cv.imwrite(res_filename, cv.cvtColor(res, cv.COLOR_RGB2BGR))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search each transformed image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leonardo\\Documents\\Repo Github\\People-Analyzer\\SR\\reid\\CelebREID_empty\\testimages\\UP\n",
      "c:\\Users\\Leonardo\\Documents\\Repo Github\\People-Analyzer\\SR\\reid\\CelebREID_empty\\testimages\\UP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leonardo\\anaconda3\\envs\\generic\\lib\\site-packages\\torchvision\\transforms\\transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Leonardo\\anaconda3\\envs\\generic\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Leonardo\\anaconda3\\envs\\generic\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loaded checkpoint 'C:\\Users\\Leonardo\\Documents\\Universita\\CVCS\\PRJ\\reid\\model.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leonardo\\Documents\\Repo Github\\People-Analyzer\\SR\\reid\\CelebREID_empty\\reid\\evaluator.py:20: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  inputs = Variable(inputs, volatile=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-Precision: 0.3 - Recall: 0.1034\n",
      "10-Precision: 0.7 - Recall: 0.1591\n",
      "10-Precision: 0.5 - Recall: 0.1471\n",
      "10-Precision: 0.3 - Recall: 0.0811\n",
      "10-Precision: 0.4 - Recall: 0.1081\n",
      "10-Precision: 0.8 - Recall: 0.2353\n",
      "10-Precision: 0.3 - Recall: 0.1579\n",
      "10-Precision: 0.9 - Recall: 0.18\n",
      "10-Precision: 0.7 - Recall: 0.2059\n",
      "10-Precision: 0.6 - Recall: 0.1667\n",
      "10-Precision: 0.9 - Recall: 0.1765\n",
      "10-Precision: 0.9 - Recall: 0.225\n",
      "10-Precision: 0.9 - Recall: 0.225\n",
      "10-Precision: 0.6 - Recall: 0.1579\n",
      "10-Precision: 0.9 - Recall: 0.2812\n",
      "10-Precision: 0.5 - Recall: 0.2174\n",
      "10-Precision: 0.2 - Recall: 0.1111\n",
      "c:\\Users\\Leonardo\\Documents\\Repo Github\\People-Analyzer\\SR\\reid\\CelebREID_empty\\testimages\\UP_FILT\n",
      "c:\\Users\\Leonardo\\Documents\\Repo Github\\People-Analyzer\\SR\\reid\\CelebREID_empty\\testimages\\UP_FILT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leonardo\\anaconda3\\envs\\generic\\lib\\site-packages\\torchvision\\transforms\\transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Leonardo\\anaconda3\\envs\\generic\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Leonardo\\anaconda3\\envs\\generic\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loaded checkpoint 'C:\\Users\\Leonardo\\Documents\\Universita\\CVCS\\PRJ\\reid\\model.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leonardo\\Documents\\Repo Github\\People-Analyzer\\SR\\reid\\CelebREID_empty\\reid\\evaluator.py:20: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  inputs = Variable(inputs, volatile=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-Precision: 0.3 - Recall: 0.1034\n",
      "10-Precision: 0.7 - Recall: 0.1591\n",
      "10-Precision: 0.3 - Recall: 0.0882\n",
      "10-Precision: 0.2 - Recall: 0.0541\n",
      "10-Precision: 0.4 - Recall: 0.1081\n",
      "10-Precision: 0.9 - Recall: 0.2647\n",
      "10-Precision: 0.2 - Recall: 0.1053\n",
      "10-Precision: 0.9 - Recall: 0.18\n",
      "10-Precision: 0.6 - Recall: 0.1765\n",
      "10-Precision: 0.6 - Recall: 0.1667\n",
      "10-Precision: 0.8 - Recall: 0.1569\n",
      "10-Precision: 0.9 - Recall: 0.225\n",
      "10-Precision: 0.9 - Recall: 0.225\n",
      "10-Precision: 0.6 - Recall: 0.1579\n",
      "10-Precision: 0.8 - Recall: 0.25\n",
      "10-Precision: 0.4 - Recall: 0.1739\n",
      "10-Precision: 0.0 - Recall: 0.0\n",
      "c:\\Users\\Leonardo\\Documents\\Repo Github\\People-Analyzer\\SR\\reid\\CelebREID_empty\\testimages\\FILT_UP\n",
      "c:\\Users\\Leonardo\\Documents\\Repo Github\\People-Analyzer\\SR\\reid\\CelebREID_empty\\testimages\\FILT_UP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leonardo\\anaconda3\\envs\\generic\\lib\\site-packages\\torchvision\\transforms\\transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Leonardo\\anaconda3\\envs\\generic\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Leonardo\\anaconda3\\envs\\generic\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loaded checkpoint 'C:\\Users\\Leonardo\\Documents\\Universita\\CVCS\\PRJ\\reid\\model.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leonardo\\Documents\\Repo Github\\People-Analyzer\\SR\\reid\\CelebREID_empty\\reid\\evaluator.py:20: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  inputs = Variable(inputs, volatile=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-Precision: 0.3 - Recall: 0.1034\n",
      "10-Precision: 0.7 - Recall: 0.1591\n",
      "10-Precision: 0.4 - Recall: 0.1176\n",
      "10-Precision: 0.3 - Recall: 0.0811\n",
      "10-Precision: 0.4 - Recall: 0.1081\n",
      "10-Precision: 0.8 - Recall: 0.2353\n",
      "10-Precision: 0.2 - Recall: 0.1053\n",
      "10-Precision: 0.9 - Recall: 0.18\n",
      "10-Precision: 0.7 - Recall: 0.2059\n",
      "10-Precision: 0.7 - Recall: 0.1944\n",
      "10-Precision: 0.8 - Recall: 0.1569\n",
      "10-Precision: 0.9 - Recall: 0.225\n",
      "10-Precision: 0.9 - Recall: 0.225\n",
      "10-Precision: 0.6 - Recall: 0.1579\n",
      "10-Precision: 0.9 - Recall: 0.2812\n",
      "10-Precision: 0.5 - Recall: 0.2174\n",
      "10-Precision: 0.1 - Recall: 0.0556\n",
      "c:\\Users\\Leonardo\\Documents\\Repo Github\\People-Analyzer\\SR\\reid\\CelebREID_empty\\testimages\\BICUBIC\n",
      "c:\\Users\\Leonardo\\Documents\\Repo Github\\People-Analyzer\\SR\\reid\\CelebREID_empty\\testimages\\BICUBIC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leonardo\\anaconda3\\envs\\generic\\lib\\site-packages\\torchvision\\transforms\\transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Leonardo\\anaconda3\\envs\\generic\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Leonardo\\anaconda3\\envs\\generic\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loaded checkpoint 'C:\\Users\\Leonardo\\Documents\\Universita\\CVCS\\PRJ\\reid\\model.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leonardo\\Documents\\Repo Github\\People-Analyzer\\SR\\reid\\CelebREID_empty\\reid\\evaluator.py:20: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  inputs = Variable(inputs, volatile=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-Precision: 0.2 - Recall: 0.069\n",
      "10-Precision: 0.5 - Recall: 0.1136\n",
      "10-Precision: 0.1 - Recall: 0.0294\n",
      "10-Precision: 0.2 - Recall: 0.0541\n",
      "10-Precision: 0.9 - Recall: 0.2432\n",
      "10-Precision: 0.3 - Recall: 0.0882\n",
      "10-Precision: 0.5 - Recall: 0.2632\n",
      "10-Precision: 0.9 - Recall: 0.18\n",
      "10-Precision: 0.2 - Recall: 0.0588\n",
      "10-Precision: 0.8 - Recall: 0.2222\n",
      "10-Precision: 0.9 - Recall: 0.1765\n",
      "10-Precision: 0.6 - Recall: 0.15\n",
      "10-Precision: 0.9 - Recall: 0.225\n",
      "10-Precision: 0.6 - Recall: 0.1579\n",
      "10-Precision: 0.4 - Recall: 0.125\n",
      "10-Precision: 0.6 - Recall: 0.2609\n",
      "10-Precision: 0.6 - Recall: 0.3333\n"
     ]
    }
   ],
   "source": [
    "from reid.CelebREID_empty.searchImage import search\n",
    "\n",
    "results = list()\n",
    "\n",
    "for i in op_list:\n",
    "    tmp_dict = dict()\n",
    "    TEST_DIR = os.path.abspath(os.getcwd())+r\"\\reid\\CelebREID_empty\\testimages\"+\"\\\\\"+i\n",
    "    print(TEST_DIR)\n",
    "    tmp_dict = search(True,TEST_DIR)\n",
    "    results.append(tmp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate AP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision UP : 0.6117647058823529\n",
      "recall UP : 0.17286470588235292\n",
      "___________________________\n",
      "precision UP_FILT : 0.5588235294117646\n",
      "recall UP_FILT : 0.15263529411764704\n",
      "___________________________\n",
      "precision FILT_UP : 0.5941176470588235\n",
      "recall FILT_UP : 0.16524705882352939\n",
      "___________________________\n",
      "precision BICUBIC : 0.5411764705882351\n",
      "recall BICUBIC : 0.16178235294117646\n",
      "___________________________\n"
     ]
    }
   ],
   "source": [
    "#primo indice raggruppa per operazione\n",
    "#secondo indice dizionario per immagineb\n",
    "p_list={}\n",
    "r_list={}\n",
    "\n",
    "for i in results:    \n",
    "    l = len(i)\n",
    "    \n",
    "    op = i[0][\"operation\"]\n",
    "    if op==\"\":\n",
    "        op=\"std\"\n",
    "    p_list[op]=0\n",
    "    r_list[op]=0\n",
    "    for ind in i:\n",
    "        p_list[op]+=ind[\"precision\"]/l\n",
    "        r_list[op]+=ind[\"recall\"]/l\n",
    "\n",
    "for i in p_list.keys():\n",
    "    print(f\"precision {i} : {p_list[i]}\")\n",
    "    print(f\"recall {i} : {r_list[i]}\")\n",
    "    print(\"___________________________\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2c15f893695056e577366fe69c89e54e0628f9b2e926d02b3ab453b18204a414"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
