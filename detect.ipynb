{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(weights=['yolov7-tiny.pt'], source='./input_images/*.jpg', img_size=640, conf_thres=0.25, iou_thres=0.45, device='', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, output='./outputs', exist_ok=True, no_trace=False, target_class='person', save_only_crop=True)\n",
      "Fusing layers... \n",
      " Convert model to Traced-model... \n",
      " traced_script_module saved! \n",
      " model is traced! \n",
      "\n",
      "4 persons Done. (391.2ms) Inference, (4.0ms) NMS\n",
      "0 person Done. (285.2ms) Inference, (3.5ms) NMS\n",
      "2 persons Done. (302.3ms) Inference, (4.0ms) NMS\n",
      "2 persons Done. (257.1ms) Inference, (2.0ms) NMS\n",
      "0 person Done. (241.5ms) Inference, (1.5ms) NMS\n",
      "2 persons Done. (172.7ms) Inference, (4.0ms) NMS\n",
      "Done. (1.829s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOR  6abb301 torch 1.13.0+cpu CPU\n",
      "\n",
      "Model Summary: 200 layers, 6219709 parameters, 229245 gradients\n",
      "c:\\Users\\pietr\\.conda\\envs\\cvcs-project\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3191.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "#!python detect.py --source ./inference/videos/test_video1.mp4 --weights yolov7-tiny.pt --name video_tiny_1 --view-img\n",
    "#!python detect.py --weights yolov7-tiny.pt --name test_image --view-img\n",
    "\n",
    "\n",
    "# add '--exist-ok' if output override is okay for you\n",
    "# add '--save_only_crop' if in output you want only crops\n",
    "# add '--target_class' and a class name for only that class outputs\n",
    "\n",
    "!python PeopleDetector/peopleDetector.py --source ./input_images/*.jpg --output ./outputs --weights yolov7-tiny.pt --exist-ok --target_class person --save_only_crop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('cvcs-project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0b6e259434f4333afa1cc5dea76fb96711b9c36ae1cda3e11247821c069fa262"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
